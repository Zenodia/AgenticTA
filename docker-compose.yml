# Docker Compose for AgenticTA
# Includes external RAG services from local rag folder

# Include external compose files
# NOTE: The 'include' directive requires Docker Compose v2.20+
# For older versions, use the Makefile targets which use multiple -f flags
# include:
#   - path: ./rag/deploy/compose/vectordb.yaml
#     env_file: ./rag/deploy/compose/.env
#   - path: ./rag/deploy/compose/docker-compose-ingestor-server.yaml
#     env_file: ./rag/deploy/compose/.env
#   - path: ./rag/deploy/compose/docker-compose-rag-server.yaml
#     env_file: ./rag/deploy/compose/.env

services:
  # ============================================
  # AgenticTA Application
  # ============================================  
  vllm:
    build:
      context: .
      dockerfile: Dockerfile.qwen_vllm
      network: host
    image: any2any
    shm_size: '64gb'
    volumes:
      # Mount source code (for development - changes reflected immediately)
      - .:/workspace
      # Mount PDF directory
      - /mnt/ZenoHD/multimodal/ckpt/:/ckpt
    environment:
      - MODEL_CHECKPOINT=/ckpt/Qwen3-Omni-30B-A3B-Instruct
      - TENSOR_PARALLEL=2
    ports:
      - "8901:8901"  # Map container port to host
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 2  # Match your TENSOR_PARALLEL value
              capabilities: [gpu]
  agenticta:
    build:
      context: .
      dockerfile: Dockerfile
      network: host
    image: ta_master:latest
    container_name: agenticta
    environment:
      - NVIDIA_API_KEY=${NVIDIA_API_KEY}
      - ASTRA_TOKEN=${ASTRA_TOKEN:-}
      - HF_TOKEN=${HF_TOKEN:-}
      - DATADOG_EMBEDDING_API_TOKEN=${DATADOG_EMBEDDING_API_TOKEN:-}
      - AI_WORKBENCH=true  # Enable Docker networking (use service names)
    volumes:
      # Mount source code (for development - changes reflected immediately)
      - .:/workspace
      # Mount PDF directory
      - /mnt/ZenoHD/astra_mnt/:/workspace/mnt/
    ports:
      - "7860:7860"  # Gradio UI
      - "2345:2345"
      - "4101:4100"
    depends_on:
      - rag-server
      - ingestor-server
    stdin_open: true
    tty: true
    command: /bin/bash
    # Uncomment below if you have GPU available and want to use it
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all
    #           capabilities: [gpu]
